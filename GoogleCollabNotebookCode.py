# -*- coding: utf-8 -*-
"""x.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/arnavjadhav/9ed9afb85861f2be388703115ba250bb/x.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install itkwidgets


import numpy as np
import nibabel as nib
import itk
import itkwidgets
from ipywidgets import interact, interactive, IntSlider, ToggleButtons
import matplotlib.pyplot as plt
from skimage.util import montage
from skimage.transform import rotate

import os
import cv2
import glob
import PIL
import shutil
# import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from skimage import data
from skimage.util import montage
import skimage.transform as skTrans
from skimage.transform import rotate
from skimage.transform import resize
from PIL import Image, ImageOps

!pip install -U nilearn
import nilearn as nl
import nibabel as nib
import nilearn.plotting as nlplt

# %matplotlib inline
import seaborn as sns
import keras
import keras.backend as K
from keras.callbacks import CSVLogger
import tensorflow as tf
from tensorflow.keras.utils import plot_model
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard
from tensorflow.keras.layers.experimental import preprocessing
import cv2

IMG_SIZE=128
SEGMENT_CLASSES = {
    0 : 'NOT tumor',
    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE
    2 : 'EDEMA',
    3 : 'ENHANCING' # original 4 -> converted into 3 later
}

# there are 155 slices per volume
# to start at 5 and use 145 slices means we will skip the first 5 and last 5
VOLUME_SLICES = 128
VOLUME_START_AT = 22 # first slice of volume that we will include

from google.colab import drive

drive.mount('/content/drive/')

"""UNLOADING THE TRAINING + VALIDATION DATA FROM THE TAR FILES"""

import tarfile
file = tarfile.open('/content/drive/MyDrive/archive (5)/BraTS2021_Training_Data.tar')

file.extractall('./brain_images')
file.close()

TRAIN_DATASET_PATH = './brain_images'

file = tarfile.open('/content/drive/MyDrive/archive (5)/BraTS2021_00621.tar')
file.extractall('./val_brain_images')
file.close()

VALIDATION_DATASET_PATH = '../val_brain_images'

##IMPORT 4 FILES FROM THE BRATS 2020 DATASET AND INSERT THEM HERE

test_image_flair = nib.load('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_flair.nii').get_fdata()
test_image_t1 = nib.load('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_t1.nii').get_fdata()
test_image_t1ce = nib.load('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_t1ce.nii').get_fdata()
test_image_t2 = nib.load('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_t2.nii').get_fdata()
test_mask = nib.load('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_seg.nii').get_fdata()

fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 10))
slice_w = 25
ax1.imshow(test_image_flair[:, :, test_image_flair.shape[1]//2 - slice_w], cmap='gray')
ax1.set_title('Image flair')
ax2.imshow(test_image_t1[:, :, test_image_t1.shape[0]//2 - slice_w], cmap='gray')
ax2.set_title('Image t1')
ax3.imshow(test_image_t1ce[:, :, test_image_t1ce.shape[0]//2 - slice_w], cmap='gray')
ax3.set_title('Image t1ce')
ax4.imshow(test_image_t2[:, :, test_image_t2.shape[0]//2 - slice_w], cmap='gray')
ax4.set_title('Image t2')
ax5.imshow(test_mask[:, :, test_mask.shape[0]//2 - slice_w])
ax5.set_title('Mask')

##IMPORT 4 FILES FROM THE BRATS 2020 DATASET AND INSERT THEM HERE

niimg = nl.image.load_img('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_flair.nii')
nimask = nl.image.load_img('/content/drive/MyDrive/archive (5)/BraTS20_Training_003_seg.nii')

fig, axes = plt.subplots(nrows=4, figsize=(30, 40))


nlplt.plot_anat(niimg,
                title='BraTS20_Training_003_flair.nii plot_anat',
                axes=axes[0])

nlplt.plot_epi(niimg,
               title='BraTS20_Training_003_flair.nii plot_epi',
               axes=axes[1])

nlplt.plot_img(niimg,
               title='BraTS20_Training_003_flair.nii plot_img',
               axes=axes[2])

nlplt.plot_roi(nimask,
               title='BraTS20_Training_003_flair.nii with mask plot_roi',
               bg_img=niimg,
               axes=axes[3], cmap='Paired')

plt.show()

import os
train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]

def pathListIntoIds(dirList):
    x = []
    for i in range(0,len(dirList)):
        x.append(dirList[i][dirList[i].rfind('/')+1:])
    return x

train_and_test_ids = pathListIntoIds(train_and_val_directories);


train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2)
train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15)

## 20% OF THE DATA GOES ARE VALIDATION_IDS AND THE OTHER 80% ARE TRAIN_TEST_IDS

## 15% OF THE TRAIN_TEST_IDS DATA IS TEST_IDS (test set) AND THE OTHER 80% IS TRAINING_IDS (training set)

def dice_coef(y_true, y_pred, smooth=1.0):
    class_num = 4
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))

        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num

    return total_loss



# define per class evaluation of dice coef

def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)

def dice_coef_edema(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)

def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)



# Computing Precision
def precision(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision


# Computing Sensitivity
def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())


# Computing Specificity
def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())


IMG_SIZE = 128

keras = tf.compat.v1.keras
Sequence = keras.utils.Sequence

class DataGenerator(Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        # Find list of IDs
        Batch_ids = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(Batch_ids)

        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, Batch_ids):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))
        y = np.zeros((self.batch_size*VOLUME_SLICES, 128, 128))
        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))
        # Generate data
        for c, i in enumerate(Batch_ids):
            case_path = os.path.join(TRAIN_DATASET_PATH, i)

            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');
            flair = nib.load(data_path).get_fdata()

            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');
            ce = nib.load(data_path).get_fdata()

            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');
            seg = nib.load(data_path).get_fdata()

            for j in range(VOLUME_SLICES):
             X[j+(VOLUME_SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))

             X[j+(VOLUME_SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))


             y[j +VOLUME_SLICES*c,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
        X = X.reshape(1,128,128,128,2)
        y = y.reshape(1,128,128,128)
        # Generate masks
        y[y==4] = 3;
        y = tf.one_hot(y, 4); ## .one_hot() turns labels into matrices

        return X/np.max(X), y

training_generator = DataGenerator(train_ids)
valid_generator = DataGenerator(val_ids)
test_generator = DataGenerator(test_ids)

csv_logger = CSVLogger('training.log', separator=',', append=False)


callbacks = [keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,
                               patience=2, verbose=1, mode='auto'),
      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=2, min_lr=0.0001, verbose=1),
      keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',
                             verbose=1, save_best_only=True, save_weights_only = True),
      csv_logger
    ]

# show number of data for each dir
def showDataLayout():
    plt.bar(["Train","Valid","Test"],
    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'red','yellow', 'green'])
    plt.legend()

    plt.ylabel('Number of images')
    plt.title('Data distribution')

    plt.show()

showDataLayout()

def conv_block(input_mat,num_filters,kernel_size,batch_norm):
  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)
  if batch_norm:
    X = BatchNormalization()(X)

  X = Activation('relu')(X)

  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)
  if batch_norm:
    X = BatchNormalization()(X)

  X = Activation('relu')(X)

  X = add([input_mat,X]);

  return X

def Vnet_3d(input_img, dropout=0.3, batch_norm=True):
    c1 = Conv3D(8, kernel_size=(5,5,5), strides=(1,1,1), padding='same')(input_img)
    if batch_norm:
        c1 = BatchNormalization()(c1)
    c1 = Activation('relu')(c1)

    c2 = Conv3D(16, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c1)
    if batch_norm:
        c2 = BatchNormalization()(c2)
    c2 = Activation('relu')(c2)

    p3 = Conv3D(32, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c2)
    p3 = Dropout(dropout)(p3)
    if batch_norm:
        p3 = BatchNormalization()(p3)
    p3 = Activation('relu')(p3)

    p4 = Conv3D(64, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(p3)
    p4 = Dropout(dropout)(p4)
    if batch_norm:
        p4 = BatchNormalization()(p4)
    p4 = Activation('relu')(p4)

    # Removed one layer here

    u7 = Conv3DTranspose(32, (2,2,2), strides=(2,2,2), padding='same')(p4)
    u7 = concatenate([u7, p3])
    if batch_norm:
        u7 = BatchNormalization()(u7)
    u7 = Activation('relu')(u7)

    u8 = Conv3DTranspose(16, (2,2,2), strides=(2,2,2), padding='same')(u7)
    u8 = concatenate([u8, c2])
    if batch_norm:
        u8 = BatchNormalization()(u8)
    u8 = Activation('relu')(u8)

    u9 = Conv3DTranspose(8, (2,2,2), strides=(2,2,2), padding='same')(u8)
    u9 = concatenate([u9, c1])
    if batch_norm:
        u9 = BatchNormalization()(u9)
    u9 = Activation('relu')(u9)

    outputs = Conv3D(4, (1,1,1), activation='softmax')(u9)

    model = Model(inputs=input_img, outputs=outputs)

    return model

input_layer = Input((128,IMG_SIZE, IMG_SIZE, 2))

model1 = Vnet_3d(input_layer)
model1.compile(loss="mean_squared_error", optimizer='adam', metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4),
                                                                                                                dice_coef, precision, sensitivity, specificity, dice_coef_necrotic,
                                                                                                                dice_coef_edema ,dice_coef_enhancing] )

model1.summary() ## Provides a summary (breakdown) of each stage of the 3D Vnet Model

history =  model1.fit(training_generator,
                     epochs = 7,
                     callbacks= callbacks,
                     validation_data = valid_generator
                     )
model1.save("model_vnet_working_model.h5")

import matplotlib.pyplot as plt
from warnings import filterwarnings
filterwarnings('ignore')

epochs = [i for i in range(7)] ##the value IN RANGE should EQUAL the number EPOCHS from ABOVE ^
fig, axs = plt.subplots(3, 2, figsize=(12, 12))

ax1, ax2, ax3, ax4, ax5, ax6 = axs.ravel()

train_acc = history.history['accuracy']
train_loss = history.history['loss']
val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']
train_mean_iou = history.history['mean_io_u']
val_mean_iou = history.history['val_mean_io_u']
train_dice_coef = history.history['dice_coef']
val_dice_coef = history.history['val_dice_coef']
train_sensitivity = history.history['sensitivity']
val_sensitivity = history.history['val_sensitivity']
train_precision = history.history['precision']
val_precision = history.history['val_precision']

sns.despine()

# Plot training and validation accuracy
ax1.plot(epochs, history.history['accuracy'], label='Train Accuracy')
ax1.plot(epochs, history.history['val_accuracy'], label='Val Accuracy')
ax1.set_title('Training and Validation Accuracy')
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Accuracy')
ax1.legend()

# Plot training and validation loss
ax2.plot(epochs, history.history['loss'], label='Train Loss')
ax2.plot(epochs, history.history['val_loss'], label='Val Loss')
ax2.set_title('Training and Validation Loss')
ax2.set_xlabel('Epochs')
ax2.set_ylabel('Loss')
ax2.legend()

# Plot training and validation mean IoU
ax3.plot(epochs, history.history['mean_io_u'], label='Train Mean IoU')
ax3.plot(epochs, history.history['val_mean_io_u'], label='Val Mean IoU')
ax3.set_title('Training and Validation Mean IoU')
ax3.set_xlabel('Epochs')
ax3.set_ylabel('Mean IoU')
ax3.legend()

# Plot training and validation dice coefficient
ax4.plot(epochs, history.history['dice_coef'], label='Train Dice Coef')
ax4.plot(epochs, history.history['val_dice_coef'], label='Val Dice Coef')
ax4.set_title('Training and Validation Dice Coefficient')
ax4.set_xlabel('Epochs')
ax4.set_ylabel('Dice Coefficient')
ax4.legend()

# Plot training and validation sensitivity
ax5.plot(epochs, history.history['sensitivity'], label='Train Sensitivity')
ax5.plot(epochs, history.history['val_sensitivity'], label='Val Sensitivity')
ax5.set_title('Training and Validation Sensitivity')
ax5.set_xlabel('Epochs')
ax5.set_ylabel('Sensitivity')
ax5.legend()

# Plot training and validation precision
ax6.plot(epochs, history.history['precision'], label='Train Precision')
ax6.plot(epochs, history.history['val_precision'], label='Val Precision')
ax6.set_title('Training and Validation Precision')
ax6.set_xlabel('Epochs')
ax6.set_ylabel('Precision')
ax6.legend()

# Adjust layout
plt.tight_layout()
plt.show()
# ax[0,0].plot(epochs, train_acc, marker='o',
#            label = 'Training Accuracy')
# ax[0,0].plot(epochs, val_acc, marker='o',
#            label = 'Validation Accuracy')
# ax[0,0].legend(frameon=False)
# ax[0,0].set_xlabel('Epochs')
# ax[0,0].set_ylabel('Accuracy')

# sns.despine()
# ax[0,1].plot(epochs, train_loss, marker='o',
#            label ='Training Loss')
# ax[0,1].plot(epochs, val_loss, marker='o',
#            label = 'Validation Loss')
# ax[0,1].legend(frameon=False)
# ax[0,1].set_xlabel('Epochs')
# ax[0,1].set_ylabel('Loss')

# sns.despine()
# ax[1,0].plot(epochs, train_mean_iou, marker='o',
#            label = 'Training MeanIoU')
# ax[1,0].plot(epochs, val_mean_iou, marker='o',
#            label = 'Validation MeanIoU')
# ax[1,0].legend(frameon=False)
# ax[1,0].set_xlabel('Epochs')
# ax[1,0].set_ylabel('MeanIoU')

# sns.despine()
# ax[1,1].plot(epochs, train_dice_coef, marker='o',
#            label = 'Training Dice_Coefficient')
# ax[1,1].plot(epochs, val_dice_coef, marker='o',
#            label = 'Validation Dice_Coefficient')
# ax[1,1].legend(frameon=False)
# ax[1,1].set_xlabel('Epochs')
# ax[1,1].set_ylabel('Dice Coefficient')

# sns.despine()
# ax[2,0].plot(epochs, train_sensitivity, marker='o',
#            label = 'Training Sensitivity')
# ax[2,0].plot(epochs, val_sensitivity, marker='o',
#            label = 'Validation Sensitivity')
# ax[2,0].legend(frameon=False)
# ax[2,0].set_xlabel('Epochs')
# ax[2,0].set_ylabel('Sensitivity')

# sns.despine()
# ax[2,1].plot(epochs, train_precision, marker='o',
#            label = 'Training Precision')
# ax[2,1].plot(epochs, val_precision, marker='o',
#            label = 'Validation Precision')
# ax[2,1].legend(frameon=False)
# ax[2,1].set_xlabel('Epochs')
# ax[2,1].set_ylabel('Precision')
# fig.show()

def predictByPath(case_path,case):
    files = next(os.walk(case_path))[2]
    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))

    vol_path = os.path.join(case_path, f'BraTS2021_Training_{case}_flair.nii');
    flair=nib.load(vol_path).get_fdata()

    vol_path = os.path.join(case_path, f'BraTS2021_Training_{case}_t1ce.nii');
    ce=nib.load(vol_path).get_fdata()



    for j in range(VOLUME_SLICES):
        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))
        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))
 #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))


    return model.predict(X/np.max(X), verbose=1)


def showPredictsById(case, start_slice = 60):
    path = f"/content/drive/MyDrive/archive (5)/BraTS2021_Training_Data.tar"
    gt = nib.load(os.path.join(path, f'BratTS2021_00655/BraTS2021_00655_seg.nii.gz')).get_fdata()
    origImage = nib.load(os.path.join(path, f'BraTS2021_Training_00655_flair.nii.gz')).get_fdata()
    p = predictByPath(path,case)

    core = p[:,:,:,1]
    edema= p[:,:,:,2]
    enhancing = p[:,:,:,3]

    plt.figure(figsize=(18, 50))
    f, axarr = plt.subplots(1,6, figsize = (18, 50))

    for i in range(6): # for each image, add brain background
        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap="gray", interpolation='none')

    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap="gray")
    axarr[0].title.set_text('Original Image Flair')
    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)
    axarr[1].imshow(curr_gt, cmap="Reds", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'
    axarr[1].title.set_text('Ground Truth Image')
    axarr[2].imshow(p[start_slice,:,:,1:4], cmap="Reds", interpolation='none', alpha=0.3)
    axarr[2].title.set_text('all classes')
    axarr[3].imshow(edema[start_slice,:,:], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')
    axarr[4].imshow(core[start_slice,:,], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')
    axarr[5].imshow(enhancing[start_slice,:,], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')
    plt.show()


showPredictsById(case=test_ids[0][-3:])
showPredictsById(case=test_ids[1][-3:])
showPredictsById(case=test_ids[2][-3:])
showPredictsById(case=test_ids[3][-3:])
showPredictsById(case=test_ids[4][-3:])
showPredictsById(case=test_ids[5][-3:])
showPredictsById(case=test_ids[6][-3:])

!tar -tf "/content/drive/MyDrive/archive (5)/BraTS2021_Training_Data.tar"

print("Evaluate on test data")
results = model1.evaluate(test_generator, callbacks= callbacks)
print("test loss, test acc:", results)